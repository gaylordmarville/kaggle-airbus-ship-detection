{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the higher resolution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CUDA devices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting CUDA devices...\")\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import SaveBestModel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/media/data-nvme/dev/datasets/airbus/trainGPU0': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "TMP_NAME = 'trainGPU0'\n",
    "DATASET_ROOT = '/media/data-nvme/dev/datasets/airbus/'\n",
    "PATH = DATASET_ROOT\n",
    "TRAIN = DATASET_ROOT + 'train_v2/'\n",
    "TEST = DATASET_ROOT + 'test_v2/'\n",
    "SEGMENTATION = DATASET_ROOT + 'train_ship_segmentations_v2.csv'\n",
    "PRETRAINED = DATASET_ROOT + 'models/resnet34s256_kaggle-airbus-l0.053-a0.981.h5'\n",
    "DETECTION_TEST_PRED = DATASET_ROOT + 'models/ship_detection.csv'\n",
    "!rm -r {PATH}{TMP_NAME} # Cleaning temp directory\n",
    "BEST_MODEL = 'Unet34_s768i2_kaggle-airbus5-3-570'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_list = ['6384c3e78.jpg'] #corrupted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = 12   #number of workers for data loader\n",
    "arch = resnet34 #specify target architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = [f for f in os.listdir(TRAIN)]\n",
    "test_names = [f for f in os.listdir(TEST)]\n",
    "for el in exclude_list:\n",
    "    if(el in train_names): train_names.remove(el)\n",
    "    if(el in test_names): test_names.remove(el)\n",
    "#5% of data in the validation set is sufficient for model evaluation\n",
    "tr_n, val_n = train_test_split(train_names, test_size=0.05, random_state=42)\n",
    "segmentation_df = pd.read_csv(os.path.join(PATH, SEGMENTATION)).set_index('ImageId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_empty(names):\n",
    "    return [name for name in names \n",
    "            if(type(segmentation_df.loc[name]['EncodedPixels']) != float)]\n",
    "\n",
    "tr_n = cut_empty(tr_n)\n",
    "val_n = cut_empty(val_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(img_id, df):\n",
    "    shape = (768,768)\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    masks = df.loc[img_id]['EncodedPixels']\n",
    "    if(type(masks) == float): return img.reshape(shape)\n",
    "    if(type(masks) == str): masks = [masks]\n",
    "    for mask in masks:\n",
    "        s = mask.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1\n",
    "    return img.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pdFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, path, transform):\n",
    "        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n",
    "        super().__init__(fnames, transform, path)\n",
    "    \n",
    "    def get_x(self, i):\n",
    "        img = open_image(os.path.join(self.path, self.fnames[i]))\n",
    "        if self.sz == 768: return img \n",
    "        else: return cv2.resize(img, (self.sz, self.sz))\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        mask = np.zeros((768,768), dtype=np.uint8) if (self.path == TEST) \\\n",
    "            else get_mask(self.fnames[i], self.segmentation_df)\n",
    "        img = Image.fromarray(mask).resize((self.sz, self.sz)).convert('RGB')\n",
    "        return np.array(img).astype(np.float32)\n",
    "    \n",
    "    def get_c(self): return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLighting(Transform):\n",
    "    def __init__(self, b, c, tfm_y=TfmType.NO):\n",
    "        super().__init__(tfm_y)\n",
    "        self.b,self.c = b,c\n",
    "\n",
    "    def set_state(self):\n",
    "        self.store.b_rand = rand0(self.b)\n",
    "        self.store.c_rand = rand0(self.c)\n",
    "\n",
    "    def do_transform(self, x, is_y):\n",
    "        if is_y and self.tfm_y != TfmType.PIXEL: return x  #add this line to fix the bug\n",
    "        b = self.store.b_rand\n",
    "        c = self.store.c_rand\n",
    "        c = -1/(c-1) if c<0 else c+1\n",
    "        x = lighting(x, b, c)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz,bs):\n",
    "    #data augmentation\n",
    "    aug_tfms = [RandomRotate(20, tfm_y=TfmType.CLASS),\n",
    "                RandomDihedral(tfm_y=TfmType.CLASS),\n",
    "                RandomLighting(0.05, 0.05, tfm_y=TfmType.CLASS)]\n",
    "    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS, \n",
    "                aug_tfms=aug_tfms)\n",
    "    tr_names = tr_n if (len(tr_n)%bs == 0) else tr_n[:-(len(tr_n)%bs)] #cut incomplete batch\n",
    "    ds = ImageData.get_ds(pdFilesDataset, (tr_names,TRAIN), \n",
    "                (val_n,TRAIN), tfms, test=(test_names,TEST))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "#     md.is_multi = False\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut,lr_cut = model_meta[arch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base():                   #load ResNet34 model\n",
    "    layers = cut_model(arch(True), cut)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def load_pretrained(model, path): #load a model pretrained on ship/no-ship classification\n",
    "    weights = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(weights, strict=False)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "    \n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "        return x[:,0]\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "            \n",
    "class UnetModel():\n",
    "    def __init__(self,model,name='Unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(input, target):\n",
    "    input = torch.sigmoid(input)\n",
    "    smooth = 1.0\n",
    "\n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.focal = FocalLoss(gamma)\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        loss = self.alpha*self.focal(input, target) - torch.log(dice_loss(input, target))\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    return 2.0 * (pred*targs).sum() / ((pred+targs).sum() + 1.0)\n",
    "\n",
    "def IoU(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    intersection = (pred*targs).sum()\n",
    "    return intersection / ((pred+targs).sum() - intersection + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_when_acc(self, metrics):\n",
    "    filename = \"{}-{}-{}\".format(self.name, self.epoch, random.randint(1,1000))\n",
    "    print(filename)\n",
    "    self.model.save(f'{filename}')\n",
    "\n",
    "SaveBestModel.save_when_acc = save_when_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_base = load_pretrained(get_base(),PRETRAINED)\n",
    "m = to_gpu(Unet34(m_base))\n",
    "models = UnetModel(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 8 cycle_len: 1 use_clr: (40, 10) SZ: 768 BS: 6 LR: [0.00001 0.0001  0.001  ] wd: 1e-07 from_model: Unet34_s768i2_kaggle-airbus5-3-570\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025409a46bcf48bd959a0c910b5ddd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet34_s768i1_kaggle-airbus5-1-265                                 \n",
      "epoch      trn_loss   val_loss   <lambda>   dice       IoU        \n",
      "    0      0.212975   0.187275   0.99886    0.871518   0.777727  \n",
      "Unet34_s768i1_kaggle-airbus5-3-610                                 \n",
      "    1      0.203502   0.188064   0.998869   0.871248   0.77799   \n",
      "Unet34_s768i1_kaggle-airbus5-5-662                                 \n",
      "    2      0.195564   0.182257   0.99888    0.874542   0.781902  \n",
      "Unet34_s768i1_kaggle-airbus5-7-171                               \n",
      "    3      0.184335   0.181102   0.998881   0.875304   0.782885  \n",
      "Unet34_s768i1_kaggle-airbus5-9-664                               \n",
      "    4      0.196117   0.179334   0.998893   0.876495   0.784628  \n",
      "Unet34_s768i1_kaggle-airbus5-11-719                                \n",
      "    5      0.177482   0.177265   0.998911   0.877768   0.786674  \n",
      "Unet34_s768i1_kaggle-airbus5-13-574                                \n",
      "    6      0.1723     0.177253   0.998908   0.877706   0.786506  \n",
      "Unet34_s768i1_kaggle-airbus5-15-398                                \n",
      "    7      0.173292   0.176538   0.998917   0.877995   0.787048  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17653753760988633,\n",
       " 0.9989169672985394,\n",
       " 0.8779947206846227,\n",
       " 0.7870484010734752]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- End of  1 ------------------------------\n",
      "epochs: 1 cycle_len: 1 use_clr: (40, 10) SZ: 768 BS: 6 LR: [0.00001 0.0001  0.001  ] wd: 1e-07 from_model: Unet34_s768i2_kaggle-airbus5-3-570\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7376349a802f432591dbd7b3a238c974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 938/6732 [27:35<2:50:28,  1.77s/it, loss=0.188]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ff2f2c5dc823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#     3      0.172256   0.16689    0.998878   0.88579    0.79573\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"cycle_len:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcycle_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"use_clr:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_clr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"SZ:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BS:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LR:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wd:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_model:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBEST_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcycle_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_clr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_save_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Unet34_s'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'i'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_kaggle-airbus5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data-nvme/dev/src/kaggle-airbus-ship-detection/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data-nvme/dev/src/kaggle-airbus-ship-detection/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data-nvme/dev/src/kaggle-airbus-ship-detection/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data-nvme/dev/src/kaggle-airbus-ship-detection/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-d205c5261a23>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-a41e7a00c979>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minvprobs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_results = collections.OrderedDict([])\n",
    "wd=1e-7\n",
    "lr = 1e-2\n",
    "lrs = np.array([lr/100,lr/10,lr])\n",
    "training_loop = [\n",
    "    [8, 1, (40,10), lrs/10, 1e-7],\n",
    "    [1, 1, (40,10), lrs/10, 1e-7],\n",
    "    [1, 1, (40,10), lrs/10, 1e-7],\n",
    "    [2, 1, (30,10), lrs/15, 1e-7],\n",
    "    [3, 1, (20,10), lrs/20, 1e-6],\n",
    "    [4, 1, (40,8), lrs/30, 1e-5],\n",
    "    [5, 1, (40,10), lrs/10, 1e-7]\n",
    "]\n",
    "sz = 768 #image size\n",
    "bs = 6  #batch size\n",
    "md = get_data(sz,bs)\n",
    "learn = ConvLearner(md, models, tmp_name=TMP_NAME)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit = MixedLoss(10.0, 2.0)\n",
    "learn.metrics=[accuracy_thresh(0.5),dice,IoU]\n",
    "learn.load(BEST_MODEL)\n",
    "i = 0\n",
    "sz = 768 #image size\n",
    "bs = 6  #batch size\n",
    "md = get_data(sz,bs)\n",
    "learn.set_data(md)\n",
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)\n",
    "\n",
    "for epochs, cycle_len, use_clr, learning_rate, wd in training_loop:\n",
    "    i+=1\n",
    "    #     epoch      trn_loss   val_loss   <lambda>   dice       IoU        \n",
    "    #     Unet34_s384i3_kaggle-airbus4-7-148                             \n",
    "    #     3      0.172256   0.16689    0.998878   0.88579    0.79573  \n",
    "    print(\"epochs:\",epochs,\"cycle_len:\",cycle_len,\"use_clr:\",use_clr,\"SZ:\", sz, \"BS:\", bs, \"LR:\", learning_rate, \"wd:\", wd, \"from_model:\", BEST_MODEL)\n",
    "    learn.fit(learning_rate,epochs,wds=wd,cycle_len=cycle_len,use_clr=use_clr, best_save_name='Unet34_s' + str(sz)  + 'i' + str(i) + \"_kaggle-airbus5\")\n",
    "    learn.sched.plot_lr()\n",
    "    learn.sched.plot_loss()\n",
    "    print(\"---------- End of \", i, \"------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
